---
title: Visual Perception to Higher Cognition
date: 
image:
  focal_point: 'top'
---

The investigation of how basic sensory experiences evolve into high-level cognitive functions unveils a compelling area of scientific inquiry. This area of study probes into the processes through which we interpret visual stimuli from our environment and integrate these with inputs from other senses, thus enabling complex cognitive tasks such as problem-solving and nuanced social interactions. 

<!--more-->

At the heart of this exploration is the understanding that visual perception is not merely about seeing but involves a sophisticated network of cognitive processes. These processes interpret and give meaning to what we see, integrating visual information with prior knowledge, experiences, and expectations.

The journey from visual perception to higher cognition also touches on the limitations and enhancements of these processes. For example, how do optical illusions trick our perception, and what does this reveal about the underlying cognitive mechanisms? Conversely, how can understanding these pathways lead to technologies and interventions that enhance cognitive function or compensate for impairments?

Notably, the advent of vision-language models marks a significant stride in research on visual abstract reasoning. For instance, the ability of large language models to tackle tasks like Raven's Progressive Matrices — a benchmark for evaluating human abstract reasoning — underscores the potential of these technologies to achieve a level of visual intelligence akin to that of humans. Our research group is keen on further exploring various machine models to compare their capabilities with human cognitive processes, aiming to deepen our understanding of the neural mechanisms underpinning high-level cognitive functions.